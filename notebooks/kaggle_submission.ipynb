{
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ECG Image Digitization - Inference Only\n",
                "\n",
                "This notebook loads a pre-trained model and generates predictions for the PhysioNet Challenge.\n",
                "\n",
                "**Competition**: [PhysioNet ECG Image Digitization](https://www.kaggle.com/competitions/physionet-ecg-image-digitization)\n",
                "\n",
                "## Pipeline Overview\n",
                "1. âœ… Environment Setup\n",
                "2. âœ… Load Pre-trained Model\n",
                "3. âœ… Run Inference\n",
                "4. âœ… Generate Submission"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Environment Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "from pathlib import Path\n",
                "\n",
                "# Detect Kaggle environment\n",
                "IS_KAGGLE = 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
                "print(f\"Running on Kaggle: {IS_KAGGLE}\")\n",
                "\n",
                "# Install dependencies if needed\n",
                "if IS_KAGGLE:\n",
                "    !pip install -q \"numpy<2\" \"pandas>=2.2.2\" segmentation-models-pytorch wfdb\n",
                "    \n",
                "    # Paths for Kaggle\n",
                "    DATA_DIR = Path('/kaggle/input/physionet-ecg-image-digitization')\n",
                "    OUTPUT_DIR = Path('/kaggle/working')\n",
                "    # Model is in the git repo attached as dataset\n",
                "    MODEL_DIR = Path('/kaggle/input/physionet-ecg-models')  # Your repo attached as dataset\n",
                "else:\n",
                "    # Local paths\n",
                "    DATA_DIR = Path('../data')\n",
                "    OUTPUT_DIR = Path('../outputs')\n",
                "    MODEL_DIR = Path('../models/exports')\n",
                "\n",
                "print(f\"Data directory: {DATA_DIR}\")\n",
                "print(f\"Model directory: {MODEL_DIR}\")\n",
                "print(f\"Output directory: {OUTPUT_DIR}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from PIL import Image\n",
                "from tqdm import tqdm\n",
                "import json\n",
                "\n",
                "# Set device\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "print(f\"\\nðŸ–¥ï¸ Device: {device}\")\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Pre-trained Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Add src to path\n",
                "if not IS_KAGGLE:\n",
                "    src_path = Path('../src')\n",
                "    if src_path.exists() and str(src_path) not in sys.path:\n",
                "        sys.path.insert(0, str(src_path.resolve()))\n",
                "\n",
                "# Import model components\n",
                "from ecg_digitization.models import ECGDigitizer\n",
                "from ecg_digitization.data import get_val_transforms\n",
                "\n",
                "# Model configuration (should match training)\n",
                "MODEL_CONFIG = {\n",
                "    'encoder_name': 'resnet50',\n",
                "    'encoder_weights': None,  # Will load from checkpoint\n",
                "    'num_leads': 12,\n",
                "    'signal_length': 5000,\n",
                "}\n",
                "\n",
                "# Image configuration\n",
                "IMAGE_SIZE = (512, 640)\n",
                "\n",
                "print(\"ðŸ“‹ Model Configuration:\")\n",
                "for k, v in MODEL_CONFIG.items():\n",
                "    print(f\"  {k}: {v}\")\n",
                "print(f\"  image_size: {IMAGE_SIZE}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load model metadata if available\n",
                "metadata_path = MODEL_DIR / 'model_metadata.json'\n",
                "if metadata_path.exists():\n",
                "    with open(metadata_path) as f:\n",
                "        model_metadata = json.load(f)\n",
                "    print(\"ðŸ“Š Model Metadata:\")\n",
                "    for k, v in model_metadata.items():\n",
                "        print(f\"  {k}: {v}\")\n",
                "else:\n",
                "    print(\"âš ï¸ No model metadata found\")\n",
                "    model_metadata = {}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create model\n",
                "print(\"\\nðŸ—ï¸ Creating model...\")\n",
                "model = ECGDigitizer(\n",
                "    encoder_name=MODEL_CONFIG['encoder_name'],\n",
                "    encoder_weights=MODEL_CONFIG['encoder_weights'],\n",
                "    num_leads=MODEL_CONFIG['num_leads'],\n",
                "    signal_length=MODEL_CONFIG['signal_length'],\n",
                ")\n",
                "\n",
                "# Load checkpoint\n",
                "checkpoint_path = MODEL_DIR / 'ecg_digitizer.pt'\n",
                "if not checkpoint_path.exists():\n",
                "    # Try alternative paths\n",
                "    alt_paths = [\n",
                "        MODEL_DIR / 'best_model.pt',\n",
                "        MODEL_DIR / 'checkpoints' / 'best_model.pt',\n",
                "    ]\n",
                "    for alt in alt_paths:\n",
                "        if alt.exists():\n",
                "            checkpoint_path = alt\n",
                "            break\n",
                "\n",
                "print(f\"ðŸ“ Loading checkpoint: {checkpoint_path}\")\n",
                "\n",
                "if checkpoint_path.exists():\n",
                "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
                "    \n",
                "    # Handle different checkpoint formats\n",
                "    if isinstance(checkpoint, dict):\n",
                "        if 'model_state_dict' in checkpoint:\n",
                "            model.load_state_dict(checkpoint['model_state_dict'])\n",
                "        elif 'state_dict' in checkpoint:\n",
                "            model.load_state_dict(checkpoint['state_dict'])\n",
                "        else:\n",
                "            model.load_state_dict(checkpoint)\n",
                "    else:\n",
                "        model.load_state_dict(checkpoint)\n",
                "    \n",
                "    print(\"âœ… Model loaded successfully\")\n",
                "else:\n",
                "    raise FileNotFoundError(f\"Checkpoint not found: {checkpoint_path}\")\n",
                "\n",
                "# Move to device and set eval mode\n",
                "model = model.to(device)\n",
                "model.eval()\n",
                "\n",
                "# Count parameters\n",
                "num_params = sum(p.numel() for p in model.parameters())\n",
                "print(f\"  Total parameters: {num_params:,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Prepare Test Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load test metadata\n",
                "test_csv = DATA_DIR / 'test.csv'\n",
                "test_df = pd.read_csv(test_csv)\n",
                "print(f\"ðŸ“Š Test samples: {len(test_df)}\")\n",
                "print(f\"Columns: {list(test_df.columns)}\")\n",
                "test_df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create transform\n",
                "transform = get_val_transforms(IMAGE_SIZE)\n",
                "\n",
                "# Find test images\n",
                "test_dir = DATA_DIR / 'test'\n",
                "test_images = list(test_dir.glob('*.png'))\n",
                "print(f\"\\nðŸ“ Found {len(test_images)} test images\")\n",
                "\n",
                "if len(test_images) > 0:\n",
                "    print(f\"  First image: {test_images[0].name}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Run Inference"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def preprocess_image(image_path, transform):\n",
                "    \"\"\"Load and preprocess an image.\"\"\"\n",
                "    image = Image.open(image_path).convert('RGB')\n",
                "    image_tensor = transform(image=np.array(image))['image']\n",
                "    return image_tensor\n",
                "\n",
                "def run_inference(model, image_paths, transform, device, batch_size=8):\n",
                "    \"\"\"Run inference on a list of images.\"\"\"\n",
                "    model.eval()\n",
                "    predictions = {}\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for i in tqdm(range(0, len(image_paths), batch_size), desc=\"Inference\"):\n",
                "            batch_paths = image_paths[i:i + batch_size]\n",
                "            batch_tensors = []\n",
                "            \n",
                "            for path in batch_paths:\n",
                "                try:\n",
                "                    tensor = preprocess_image(path, transform)\n",
                "                    batch_tensors.append(tensor)\n",
                "                except Exception as e:\n",
                "                    print(f\"Warning: Failed to process {path}: {e}\")\n",
                "                    continue\n",
                "            \n",
                "            if len(batch_tensors) == 0:\n",
                "                continue\n",
                "            \n",
                "            # Stack batch\n",
                "            batch = torch.stack(batch_tensors).to(device)\n",
                "            \n",
                "            # Forward pass\n",
                "            outputs = model(batch, target_length=5000)\n",
                "            signals = outputs['signals'].cpu().numpy()\n",
                "            \n",
                "            # Store predictions\n",
                "            for j, path in enumerate(batch_paths[:len(signals)]):\n",
                "                sample_id = path.stem  # Get filename without extension\n",
                "                predictions[sample_id] = signals[j]\n",
                "    \n",
                "    return predictions\n",
                "\n",
                "print(\"\\nðŸ”® Running inference...\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run inference\n",
                "predictions = run_inference(\n",
                "    model=model,\n",
                "    image_paths=test_images,\n",
                "    transform=transform,\n",
                "    device=device,\n",
                "    batch_size=8,\n",
                ")\n",
                "\n",
                "print(f\"\\nâœ… Generated predictions for {len(predictions)} samples\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Generate Submission"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Lead names for ECG\n",
                "LEAD_NAMES = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
                "\n",
                "def create_submission(predictions, lead_names=LEAD_NAMES):\n",
                "    \"\"\"Create submission DataFrame in required format.\"\"\"\n",
                "    rows = []\n",
                "    \n",
                "    for sample_id, signal in predictions.items():\n",
                "        # Signal shape: [num_leads, signal_length]\n",
                "        for lead_idx, lead_name in enumerate(lead_names):\n",
                "            if lead_idx < signal.shape[0]:\n",
                "                # Convert signal to list of values\n",
                "                signal_values = signal[lead_idx].tolist()\n",
                "                \n",
                "                rows.append({\n",
                "                    'id': f\"{sample_id}_{lead_name}\",\n",
                "                    'signal': signal_values,\n",
                "                })\n",
                "    \n",
                "    return pd.DataFrame(rows)\n",
                "\n",
                "print(\"\\nðŸ“ Creating submission file...\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create submission DataFrame\n",
                "submission_df = create_submission(predictions)\n",
                "\n",
                "print(f\"Submission shape: {submission_df.shape}\")\n",
                "print(f\"Columns: {list(submission_df.columns)}\")\n",
                "submission_df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save submission\n",
                "submission_path = OUTPUT_DIR / 'submission.parquet'\n",
                "submission_df.to_parquet(submission_path, index=False)\n",
                "\n",
                "print(f\"\\nâœ… Submission saved: {submission_path}\")\n",
                "print(f\"  File size: {submission_path.stat().st_size / 1024 / 1024:.2f} MB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Visualize Sample Predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Visualize a few predictions\n",
                "sample_ids = list(predictions.keys())[:3]\n",
                "\n",
                "fig, axes = plt.subplots(len(sample_ids), 1, figsize=(14, 4 * len(sample_ids)))\n",
                "if len(sample_ids) == 1:\n",
                "    axes = [axes]\n",
                "\n",
                "for idx, sample_id in enumerate(sample_ids):\n",
                "    signal = predictions[sample_id]\n",
                "    time = np.arange(signal.shape[1]) / 500  # 500 Hz sampling rate\n",
                "    \n",
                "    # Plot all 12 leads with offset\n",
                "    for lead_idx in range(min(12, signal.shape[0])):\n",
                "        axes[idx].plot(\n",
                "            time, \n",
                "            signal[lead_idx, :] + lead_idx * 2, \n",
                "            linewidth=0.8, \n",
                "            alpha=0.8,\n",
                "            label=LEAD_NAMES[lead_idx] if lead_idx < len(LEAD_NAMES) else f'Lead {lead_idx}'\n",
                "        )\n",
                "    \n",
                "    axes[idx].set_xlabel('Time (s)', fontsize=11)\n",
                "    axes[idx].set_ylabel('Lead (offset)', fontsize=11)\n",
                "    axes[idx].set_title(f'Sample: {sample_id}', fontsize=12, fontweight='bold')\n",
                "    axes[idx].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\nâœ… Displayed {len(sample_ids)} sample predictions\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸŽ‰ Submission Complete!\n",
                "\n",
                "Your submission file has been generated:\n",
                "- **File**: `submission.parquet`\n",
                "- **Format**: Parquet with columns `id` and `signal`\n",
                "\n",
                "### Next Steps\n",
                "1. Submit to the [PhysioNet ECG Image Digitization competition](https://www.kaggle.com/competitions/physionet-ecg-image-digitization)\n",
                "2. Check your leaderboard score\n",
                "\n",
                "### Model Info\n",
                "- **Architecture**: ECGDigitizer (ResNet50 encoder + Signal Regression Head)\n",
                "- **Input**: ECG paper images (RGB)\n",
                "- **Output**: 12-lead ECG signals (5000 samples each)"
            ]
        }
    ]
}