{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ECG Image Digitization - Kaggle Submission Notebook\n\nThis notebook trains an ECG digitization model and generates a submission file for the PhysioNet Challenge.\n\n**Competition**: [PhysioNet ECG Image Digitization](https://www.kaggle.com/competitions/physionet-ecg-image-digitization)\n\n## Pipeline Overview\n1. ‚úÖ Environment Setup\n2. ‚úÖ Dataset Loading\n3. ‚úÖ Model Training\n4. ‚úÖ Inference\n5. ‚úÖ Submission Generation","metadata":{}},{"cell_type":"markdown","source":"## 1. Environment Setup\n\nInstall dependencies and detect Kaggle environment.","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nfrom pathlib import Path\n\n# Detect Kaggle environment\nIS_KAGGLE = 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\nprint(f\"Running on Kaggle: {IS_KAGGLE}\")\n\n# Install additional dependencies if needed\nif IS_KAGGLE:\n    !pip install -q segmentation-models-pytorch hydra-core omegaconf wfdb neurokit2 biosppy loguru rich\n    \n    # Set paths for Kaggle\n    DATA_DIR = Path('/kaggle/input/physionet-ecg-image-digitization')\n    OUTPUT_DIR = Path('/kaggle/working')\nelse:\n    # Local paths\n    DATA_DIR = Path('../data')\n    OUTPUT_DIR = Path('../models')\n\nprint(f\"Data directory: {DATA_DIR}\")\nprint(f\"Output directory: {OUTPUT_DIR}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Dataset Loading\n\nLoad and verify the competition dataset.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# List available files\nif DATA_DIR.exists():\n    print(\"\\nüìÅ Available files:\")\n    for item in sorted(DATA_DIR.rglob('*')):\n        if item.is_file():\n            print(f\"  {item.relative_to(DATA_DIR)}\")\nelse:\n    print(f\"‚ö†Ô∏è  Data directory not found: {DATA_DIR}\")\n    print(\"Please ensure the competition data is linked/downloaded.\")\n\n# Load metadata if available\ntrain_csv = DATA_DIR / 'train.csv'\nif train_csv.exists():\n    train_df = pd.read_csv(train_csv)\n    print(f\"\\nüìä Training samples: {len(train_df)}\")\n    print(f\"Columns: {list(train_df.columns)}\")\n    display(train_df.head())\nelse:\n    print(f\"‚ö†Ô∏è  Training metadata not found: {train_csv}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Visualize Sample ECG Images","metadata":{}},{"cell_type":"code","source":"# Visualize a few sample images\ntrain_images = DATA_DIR / 'train'\nif train_images.exists():\n    image_files = list(train_images.glob('*.png'))[:6]\n    \n    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n    axes = axes.flatten()\n    \n    for idx, img_path in enumerate(image_files):\n        img = Image.open(img_path)\n        axes[idx].imshow(img, cmap='gray')\n        axes[idx].set_title(img_path.name, fontsize=10)\n        axes[idx].axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n    print(f\"\\n‚úÖ Displayed {len(image_files)} sample images\")\nelse:\n    print(f\"‚ö†Ô∏è  Training images directory not found: {train_images}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Configure Training Pipeline\n\nSet up Hydra configuration programmatically with MLflow **disabled** for Kaggle.","metadata":{}},{"cell_type":"code","source":"from omegaconf import OmegaConf, DictConfig\nimport torch\n\n# Create configuration\ncfg = OmegaConf.create({\n    'project': {\n        'name': 'ecg-digitization',\n        'version': '0.1.0',\n        'seed': 42,\n    },\n    'mlflow': {\n        'enabled': False,  # DISABLED for Kaggle\n        'tracking_uri': 'http://localhost:5050',\n        'experiment_name': 'ecg-digitization-kaggle',\n    },\n    'paths': {\n        'data_dir': str(DATA_DIR),\n        'train_dir': str(DATA_DIR / 'train'),\n        'test_dir': str(DATA_DIR / 'test'),\n        'output_dir': str(OUTPUT_DIR / 'models'),\n        'checkpoint_dir': str(OUTPUT_DIR / 'checkpoints'),\n        'submission_dir': str(OUTPUT_DIR),\n        'log_dir': str(OUTPUT_DIR / 'logs'),\n    },\n    'data': {\n        'image_size': [512, 512],\n        'batch_size': 4 if IS_KAGGLE else 8,  # Smaller batch for Kaggle GPU\n        'num_workers': 2,\n        'pin_memory': True,\n        'augment_prob': 0.5,\n    },\n    'model': {\n        'encoder_name': 'resnet50',\n        'encoder_weights': 'imagenet',\n        'num_leads': 12,\n        'signal_length': 5000,\n    },\n    'training': {\n        'epochs': 10 if IS_KAGGLE else 20,  # Fewer epochs for Kaggle time limits\n        'learning_rate': 1e-4,\n        'weight_decay': 1e-5,\n        'val_split': 0.2,\n    },\n    'approach': {\n        'method': 'baseline',\n    },\n})\n\n# Set random seed\ntorch.manual_seed(cfg.project.seed)\nnp.random.seed(cfg.project.seed)\n\n# Create output directories\nfor dir_path in [cfg.paths.output_dir, cfg.paths.checkpoint_dir, cfg.paths.log_dir]:\n    Path(dir_path).mkdir(parents=True, exist_ok=True)\n\nprint(\"\\n‚öôÔ∏è  Configuration:\")\nprint(OmegaConf.to_yaml(cfg))\nprint(f\"\\nüîß MLflow tracking: {'‚úÖ ENABLED' if cfg.mlflow.enabled else '‚ùå DISABLED'}\")\nprint(f\"üñ•Ô∏è  Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Model Training\n\nTrain the ECG digitization model using our pipeline.","metadata":{}},{"cell_type":"code","source":"# Add src to path if running locally\nif not IS_KAGGLE:\n    src_path = Path('../src')\n    if src_path.exists() and str(src_path) not in sys.path:\n        sys.path.insert(0, str(src_path.resolve()))\n\nfrom torch.utils.data import DataLoader, random_split\nfrom ecg_digitization.data import ECGImageDataset, get_train_transforms, get_val_transforms, collate_fn\nfrom ecg_digitization.models import ECGDigitizer\nfrom ecg_digitization.training import ECGTrainer, CombinedLoss\nfrom ecg_digitization.utils.mlflow_utils import create_mlflow_tracker\nfrom ecg_digitization.utils import setup_logging\n\n# Setup logging\nsetup_logging(cfg.paths.log_dir)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"\\nüéØ Training on: {device}\")\n\n# Initialize MLflow tracker (will be no-op since mlflow.enabled=False)\nmlflow_tracker = create_mlflow_tracker(\n    enabled=cfg.mlflow.enabled,\n    tracking_uri=cfg.mlflow.tracking_uri,\n    experiment_name=cfg.mlflow.experiment_name,\n    run_name=\"kaggle_training\",\n    tags={\"environment\": \"kaggle\" if IS_KAGGLE else \"local\"},\n)\n\n# Start MLflow run (no-op if disabled)\nmlflow_tracker.start_run()\n\ntry:\n    # Log config (no-op if disabled)\n    config_dict = OmegaConf.to_container(cfg, resolve=True)\n    mlflow_tracker.log_config(config_dict)\n    \n    # Create datasets\n    print(\"\\nüì¶ Preparing datasets...\")\n    train_transform = get_train_transforms(tuple(cfg.data.image_size), cfg.data.augment_prob)\n    val_transform = get_val_transforms(tuple(cfg.data.image_size))\n    \n    full_dataset = ECGImageDataset(\n        cfg.paths.data_dir,\n        transform=train_transform,\n        is_train=True,\n    )\n    \n    # Split into train/val\n    val_size = int(len(full_dataset) * cfg.training.val_split)\n    train_size = len(full_dataset) - val_size\n    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n    val_dataset.dataset.transform = val_transform\n    \n    print(f\"  Training samples: {train_size}\")\n    print(f\"  Validation samples: {val_size}\")\n    \n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=cfg.data.batch_size,\n        shuffle=True,\n        num_workers=cfg.data.num_workers,\n        pin_memory=cfg.data.pin_memory,\n        collate_fn=collate_fn,\n    )\n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=cfg.data.batch_size,\n        shuffle=False,\n        num_workers=cfg.data.num_workers,\n        pin_memory=cfg.data.pin_memory,\n        collate_fn=collate_fn,\n    )\n    \n    # Create model\n    print(\"\\nüèóÔ∏è  Building model...\")\n    model = ECGDigitizer(\n        encoder_name=cfg.model.encoder_name,\n        encoder_weights=cfg.model.encoder_weights,\n        num_leads=cfg.model.num_leads,\n        signal_length=cfg.model.signal_length,\n    )\n    \n    # Setup training\n    optimizer = torch.optim.AdamW(\n        model.parameters(),\n        lr=cfg.training.learning_rate,\n        weight_decay=cfg.training.weight_decay,\n    )\n    \n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n        optimizer, T_max=cfg.training.epochs\n    )\n    \n    criterion = CombinedLoss()\n    \n    # Create trainer with MLflow integration (will be no-op)\n    trainer = ECGTrainer(\n        model=model,\n        train_loader=train_loader,\n        val_loader=val_loader,\n        optimizer=optimizer,\n        criterion=criterion,\n        scheduler=scheduler,\n        device=device,\n        checkpoint_dir=cfg.paths.checkpoint_dir,\n        mlflow_tracker=mlflow_tracker,\n    )\n    \n    # Train model\n    print(f\"\\nüöÄ Starting training for {cfg.training.epochs} epochs...\")\n    print(\"=\" * 60)\n    trainer.train(cfg.training.epochs)\n    print(\"=\" * 60)\n    print(\"\\n‚úÖ Training completed!\")\n    \n    # Plot training curves\n    fig, ax = plt.subplots(figsize=(10, 6))\n    epochs = range(1, len(trainer.train_losses) + 1)\n    ax.plot(epochs, trainer.train_losses, 'b-', label='Training Loss', linewidth=2)\n    ax.plot(epochs, trainer.val_losses, 'r-', label='Validation Loss', linewidth=2)\n    ax.set_xlabel('Epoch', fontsize=12)\n    ax.set_ylabel('Loss', fontsize=12)\n    ax.set_title('Training Progress', fontsize=14, fontweight='bold')\n    ax.legend(fontsize=11)\n    ax.grid(True, alpha=0.3)\n    plt.tight_layout()\n    plt.show()\n    \n    print(f\"\\nüìà Best validation loss: {trainer.best_val_loss:.4f}\")\n    \n    # End MLflow run (no-op if disabled)\n    mlflow_tracker.end_run(status=\"FINISHED\")\n    \nexcept Exception as e:\n    print(f\"\\n‚ùå Training failed: {e}\")\n    mlflow_tracker.end_run(status=\"FAILED\")\n    raise","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Inference & Submission Generation\n\nGenerate predictions on the test set and create submission file.","metadata":{}},{"cell_type":"code","source":"from ecg_digitization.inference import ECGPredictor\n\nprint(\"\\nüîÆ Running inference on test set...\")\n\n# Prepare test dataset\ntest_transform = get_val_transforms(tuple(cfg.data.image_size))\ntest_dataset = ECGImageDataset(\n    cfg.paths.data_dir,\n    transform=test_transform,\n    is_train=False,\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=cfg.data.batch_size,\n    shuffle=False,\n    num_workers=cfg.data.num_workers,\n    collate_fn=collate_fn,\n)\n\nprint(f\"  Test samples: {len(test_dataset)}\")\n\n# Load best model\nmodel = ECGDigitizer(\n    encoder_name=cfg.model.encoder_name,\n    num_leads=cfg.model.num_leads,\n    signal_length=cfg.model.signal_length,\n)\n\npredictor = ECGPredictor(\n    model=model,\n    checkpoint_path=f\"{cfg.paths.checkpoint_dir}/best_model.pt\",\n    device=device,\n)\n\n# Generate predictions\npredictions = predictor.predict(test_loader)\nprint(f\"\\n‚úÖ Generated predictions for {len(predictions)} samples\")\n\n# Load test metadata\ntest_csv = Path(cfg.paths.data_dir) / 'test.csv'\nif test_csv.exists():\n    metadata = pd.read_csv(test_csv)\n    print(f\"  Loaded metadata for {len(metadata)} test samples\")\nelse:\n    metadata = None\n    print(\"  ‚ö†Ô∏è  No test metadata found\")\n\n# Generate submission file\nsubmission_path = Path(cfg.paths.submission_dir) / 'submission.parquet'\npredictor.generate_submission(\n    predictions,\n    str(submission_path),\n    metadata,\n)\n\nprint(f\"\\nüìù Submission file created: {submission_path}\")\nprint(f\"  File size: {submission_path.stat().st_size / 1024 / 1024:.2f} MB\")\n\n# Verify submission format\nif submission_path.exists():\n    submission_df = pd.read_parquet(submission_path)\n    print(f\"\\n‚úÖ Submission verification:\")\n    print(f\"  Shape: {submission_df.shape}\")\n    print(f\"  Columns: {list(submission_df.columns)}\")\n    display(submission_df.head())\nelse:\n    print(\"\\n‚ùå Submission file not created!\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Visualize Sample Predictions\n\nDisplay some sample predictions to verify quality.","metadata":{}},{"cell_type":"code","source":"# Visualize a few predictions\nnum_samples = min(3, len(predictions))\n\nfig, axes = plt.subplots(num_samples, 1, figsize=(14, 4 * num_samples))\nif num_samples == 1:\n    axes = [axes]\n\nfor idx in range(num_samples):\n    pred = predictions[idx]\n    time = np.arange(pred.shape[1]) / 500  # Assuming 500 Hz sampling rate\n    \n    # Plot all 12 leads\n    for lead_idx in range(min(12, pred.shape[0])):\n        axes[idx].plot(time, pred[lead_idx, :] + lead_idx * 2, linewidth=0.8, alpha=0.8)\n    \n    axes[idx].set_xlabel('Time (s)', fontsize=11)\n    axes[idx].set_ylabel('Lead (offset)', fontsize=11)\n    axes[idx].set_title(f'Sample {idx + 1} - Predicted ECG Signals', fontsize=12, fontweight='bold')\n    axes[idx].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\n‚úÖ Displayed {num_samples} sample predictions\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üéâ Submission Ready!\n\nYour submission file has been generated and is ready to submit to Kaggle.\n\n**Next Steps**:\n1. Download `submission.parquet` from the output directory\n2. Submit to the [PhysioNet ECG Image Digitization competition](https://www.kaggle.com/competitions/physionet-ecg-image-digitization)\n3. Check your leaderboard score!\n\n**Note**: MLflow tracking was disabled for this Kaggle run. To enable tracking locally with MLflow, set `mlflow.enabled=true` in the configuration.","metadata":{}}]}