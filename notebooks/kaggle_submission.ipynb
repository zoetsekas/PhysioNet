{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ECG Image Digitization - Kaggle Submission Notebook\n",
                "\n",
                "This notebook trains an ECG digitization model and generates a submission file for the PhysioNet Challenge.\n",
                "\n",
                "**Competition**: [PhysioNet ECG Image Digitization](https://www.kaggle.com/competitions/physionet-ecg-image-digitization)\n",
                "\n",
                "## Pipeline Overview\n",
                "1. ‚úÖ Environment Setup\n",
                "2. ‚úÖ Dataset Loading\n",
                "3. ‚úÖ Model Training\n",
                "4. ‚úÖ Inference\n",
                "5. ‚úÖ Submission Generation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Environment Setup\n",
                "\n",
                "Install dependencies and detect Kaggle environment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "from pathlib import Path\n",
                "\n",
                "# Detect Kaggle environment\n",
                "IS_KAGGLE = 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
                "print(f\"Running on Kaggle: {IS_KAGGLE}\")\n",
                "\n",
                "# Install additional dependencies if needed\n",
                "if IS_KAGGLE:\n",
                "    # Note: Pinning numpy < 2.0.0 and upgrading pandas avoids a common compatibility error:\n",
                "    # \"TypeError: Cannot convert numpy.ndarray to numpy.ndarray\" during read_csv\n",
                "    !pip install -q \"numpy<2.0.0\" \"pandas>=2.2.2\" segmentation-models-pytorch hydra-core omegaconf wfdb neurokit2 biosppy loguru rich\n",
                "    \n",
                "    # Set paths for Kaggle\n",
                "    DATA_DIR = Path('/kaggle/input/physionet-ecg-image-digitization')\n",
                "    OUTPUT_DIR = Path('/kaggle/working')\n",
                "else:\n",
                "    # Local paths\n",
                "    DATA_DIR = Path('../data')\n",
                "    OUTPUT_DIR = Path('../models')\n",
                "\n",
                "print(f\"Data directory: {DATA_DIR}\")\n",
                "print(f\"Output directory: {OUTPUT_DIR}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Dataset Loading\n",
                "\n",
                "Load and verify the competition dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from PIL import Image\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# List available files (limit to first 10 for readability)\n",
                "if DATA_DIR.exists():\n",
                "    print(\"\\nüìÅ Sample files:\")\n",
                "    for idx, item in enumerate(sorted(DATA_DIR.rglob('*'))):\n",
                "        if item.is_file() and idx < 10:\n",
                "            print(f\"  {item.relative_to(DATA_DIR)}\")\n",
                "        elif idx >= 10:\n",
                "            print(\"  ... (more files)\")\n",
                "            break\n",
                "else:\n",
                "    print(f\"‚ö†Ô∏è  Data directory not found: {DATA_DIR}\")\n",
                "    print(\"Please ensure the competition data is linked/downloaded.\")\n",
                "\n",
                "# Load metadata if available\n",
                "train_csv = DATA_DIR / 'train.csv'\n",
                "if train_csv.exists():\n",
                "    train_df = pd.read_csv(train_csv)\n",
                "    print(f\"\\nüìä Training samples: {len(train_df)}\")\n",
                "    print(f\"Columns: {list(train_df.columns)}\")\n",
                "    display(train_df.head())\n",
                "else:\n",
                "    print(f\"‚ö†Ô∏è  Training metadata not found: {train_csv}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualize Sample ECG Images"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize a few sample images\n",
                "# Images are in nested directories (train/ecg001/, train/ecg002/, etc.)\n",
                "train_images = DATA_DIR / 'train'\n",
                "if train_images.exists():\n",
                "    # Use rglob to recursively find images in subdirectories\n",
                "    image_files = list(train_images.rglob('*.png'))[:6]\n",
                "    \n",
                "    if len(image_files) > 0:\n",
                "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
                "        axes = axes.flatten()\n",
                "        \n",
                "        for idx, img_path in enumerate(image_files):\n",
                "            img = Image.open(img_path)\n",
                "            axes[idx].imshow(img, cmap='gray')\n",
                "            # Show relative path for context\n",
                "            axes[idx].set_title(str(img_path.relative_to(train_images)), fontsize=8)\n",
                "            axes[idx].axis('off')\n",
                "        \n",
                "        plt.tight_layout()\n",
                "        plt.show()\n",
                "        print(f\"\\n‚úÖ Displayed {len(image_files)} sample images\")\n",
                "    else:\n",
                "        print(f\"‚ö†Ô∏è  No PNG images found in {train_images}\")\n",
                "else:\n",
                "    print(f\"‚ö†Ô∏è  Training images directory not found: {train_images}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Configure Training Pipeline\n",
                "\n",
                "Set up Hydra configuration programmatically with MLflow **disabled** for Kaggle."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from omegaconf import OmegaConf, DictConfig\n",
                "import torch\n",
                "\n",
                "# Create configuration\n",
                "cfg = OmegaConf.create({\n",
                "    'project': {\n",
                "        'name': 'ecg-digitization',\n",
                "        'version': '0.1.0',\n",
                "        'seed': 42,\n",
                "    },\n",
                "    'mlflow': {\n",
                "        'enabled': False,  # DISABLED for Kaggle\n",
                "        'tracking_uri': 'http://localhost:5050',\n",
                "        'experiment_name': 'ecg-digitization-kaggle',\n",
                "    },\n",
                "    'paths': {\n",
                "        'data_dir': str(DATA_DIR),\n",
                "        'train_dir': str(DATA_DIR / 'train'),\n",
                "        'test_dir': str(DATA_DIR / 'test'),\n",
                "        'output_dir': str(OUTPUT_DIR / 'models'),\n",
                "        'checkpoint_dir': str(OUTPUT_DIR / 'checkpoints'),\n",
                "        'submission_dir': str(OUTPUT_DIR),\n",
                "        'log_dir': str(OUTPUT_DIR / 'logs'),\n",
                "    },\n",
                "    'data': {\n",
                "        'image_size': [512, 512],\n",
                "        'batch_size': 4 if IS_KAGGLE else 8,  # Smaller batch for Kaggle GPU\n",
                "        'num_workers': 2,\n",
                "        'pin_memory': True,\n",
                "        'augment_prob': 0.5,\n",
                "    },\n",
                "    'model': {\n",
                "        'encoder_name': 'resnet50',\n",
                "        'encoder_weights': 'imagenet',\n",
                "        'num_leads': 12,\n",
                "        'signal_length': 5000,\n",
                "    },\n",
                "    'training': {\n",
                "        'epochs': 10 if IS_KAGGLE else 20,  # Fewer epochs for Kaggle time limits\n",
                "        'learning_rate': 1e-4,\n",
                "        'weight_decay': 1e-5,\n",
                "        'val_split': 0.2,\n",
                "    },\n",
                "    'approach': {\n",
                "        'method': 'baseline',\n",
                "    },\n",
                "})\n",
                "\n",
                "# Set random seed\n",
                "torch.manual_seed(cfg.project.seed)\n",
                "np.random.seed(cfg.project.seed)\n",
                "\n",
                "# Create output directories\n",
                "for dir_path in [cfg.paths.output_dir, cfg.paths.checkpoint_dir, cfg.paths.log_dir]:\n",
                "    Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "print(\"\\n‚öôÔ∏è  Configuration:\")\n",
                "print(OmegaConf.to_yaml(cfg))\n",
                "print(f\"\\nüîß MLflow tracking: {'‚úÖ ENABLED' if cfg.mlflow.enabled else '‚ùå DISABLED'}\")\n",
                "print(f\"üñ•Ô∏è  Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Model Training\n",
                "\n",
                "Train the ECG digitization model using our pipeline."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Add src to path if running locally\n",
                "if not IS_KAGGLE:\n",
                "    src_path = Path('../src')\n",
                "    if src_path.exists() and str(src_path) not in sys.path:\n",
                "        sys.path.insert(0, str(src_path.resolve()))\n",
                "\n",
                "from torch.utils.data import DataLoader, random_split\n",
                "from ecg_digitization.data import ECGImageDataset, get_train_transforms, get_val_transforms, collate_fn\n",
                "from ecg_digitization.models import ECGDigitizer\n",
                "from ecg_digitization.training import ECGTrainer, CombinedLoss\n",
                "from ecg_digitization.utils.mlflow_utils import create_mlflow_tracker\n",
                "from ecg_digitization.utils import setup_logging\n",
                "\n",
                "# Setup logging\n",
                "setup_logging(cfg.paths.log_dir)\n",
                "\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"\\nüéØ Training on: {device}\")\n",
                "\n",
                "# Initialize MLflow tracker (will be no-op since mlflow.enabled=False)\n",
                "mlflow_tracker = create_mlflow_tracker(\n",
                "    enabled=cfg.mlflow.enabled,\n",
                "    tracking_uri=cfg.mlflow.tracking_uri,\n",
                "    experiment_name=cfg.mlflow.experiment_name,\n",
                "    run_name=\"kaggle_training\",\n",
                "    tags={\"environment\": \"kaggle\" if IS_KAGGLE else \"local\"},\n",
                ")\n",
                "\n",
                "# Start MLflow run (no-op if disabled)\n",
                "mlflow_tracker.start_run()\n",
                "\n",
                "try:\n",
                "    # Log config (no-op if disabled)\n",
                "    config_dict = OmegaConf.to_container(cfg, resolve=True)\n",
                "    mlflow_tracker.log_config(config_dict)\n",
                "    \n",
                "    # Create datasets\n",
                "    print(\"\\nüì¶ Preparing datasets...\")\n",
                "    train_transform = get_train_transforms(tuple(cfg.data.image_size), cfg.data.augment_prob)\n",
                "    val_transform = get_val_transforms(tuple(cfg.data.image_size))\n",
                "    \n",
                "    full_dataset = ECGImageDataset(\n",
                "        cfg.paths.data_dir,\n",
                "        transform=train_transform,\n",
                "        is_train=True,\n",
                "    )\n",
                "    \n",
                "    # Split into train/val\n",
                "    val_size = int(len(full_dataset) * cfg.training.val_split)\n",
                "    train_size = len(full_dataset) - val_size\n",
                "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
                "    val_dataset.dataset.transform = val_transform\n",
                "    \n",
                "    print(f\"  Training samples: {train_size}\")\n",
                "    print(f\"  Validation samples: {val_size}\")\n",
                "    \n",
                "    train_loader = DataLoader(\n",
                "        train_dataset,\n",
                "        batch_size=cfg.data.batch_size,\n",
                "        shuffle=True,\n",
                "        num_workers=cfg.data.num_workers,\n",
                "        pin_memory=cfg.data.pin_memory,\n",
                "        collate_fn=collate_fn,\n",
                "    )\n",
                "    val_loader = DataLoader(\n",
                "        val_dataset,\n",
                "        batch_size=cfg.data.batch_size,\n",
                "        shuffle=False,\n",
                "        num_workers=cfg.data.num_workers,\n",
                "        pin_memory=cfg.data.pin_memory,\n",
                "        collate_fn=collate_fn,\n",
                "    )\n",
                "    \n",
                "    # Create model\n",
                "    print(\"\\nüèóÔ∏è  Building model...\")\n",
                "    model = ECGDigitizer(\n",
                "        encoder_name=cfg.model.encoder_name,\n",
                "        encoder_weights=cfg.model.encoder_weights,\n",
                "        num_leads=cfg.model.num_leads,\n",
                "        signal_length=cfg.model.signal_length,\n",
                "    )\n",
                "    \n",
                "    # Setup training\n",
                "    optimizer = torch.optim.AdamW(\n",
                "        model.parameters(),\n",
                "        lr=cfg.training.learning_rate,\n",
                "        weight_decay=cfg.training.weight_decay,\n",
                "    )\n",
                "    \n",
                "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
                "        optimizer, T_max=cfg.training.epochs\n",
                "    )\n",
                "    \n",
                "    criterion = CombinedLoss()\n",
                "    \n",
                "    # Create trainer with MLflow integration (will be no-op)\n",
                "    trainer = ECGTrainer(\n",
                "        model=model,\n",
                "        train_loader=train_loader,\n",
                "        val_loader=val_loader,\n",
                "        optimizer=optimizer,\n",
                "        criterion=criterion,\n",
                "        scheduler=scheduler,\n",
                "        device=device,\n",
                "        checkpoint_dir=cfg.paths.checkpoint_dir,\n",
                "        mlflow_tracker=mlflow_tracker,\n",
                "    )\n",
                "    \n",
                "    # Train model\n",
                "    print(f\"\\nüöÄ Starting training for {cfg.training.epochs} epochs...\")\n",
                "    print(\"=\" * 60)\n",
                "    trainer.train(cfg.training.epochs)\n",
                "    print(\"=\" * 60)\n",
                "    print(\"\\n‚úÖ Training completed!\")\n",
                "    \n",
                "    # Plot training curves\n",
                "    fig, ax = plt.subplots(figsize=(10, 6))\n",
                "    epochs = range(1, len(trainer.train_losses) + 1)\n",
                "    ax.plot(epochs, trainer.train_losses, 'b-', label='Training Loss', linewidth=2)\n",
                "    ax.plot(epochs, trainer.val_losses, 'r-', label='Validation Loss', linewidth=2)\n",
                "    ax.set_xlabel('Epoch', fontsize=12)\n",
                "    ax.set_ylabel('Loss', fontsize=12)\n",
                "    ax.set_title('Training Progress', fontsize=14, fontweight='bold')\n",
                "    ax.legend(fontsize=11)\n",
                "    ax.grid(True, alpha=0.3)\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "    \n",
                "    print(f\"\\nüìà Best validation loss: {trainer.best_val_loss:.4f}\")\n",
                "    \n",
                "    # End MLflow run (no-op if disabled)\n",
                "    mlflow_tracker.end_run(status=\"FINISHED\")\n",
                "    \n",
                "except Exception as e:\n",
                "    print(f\"\\n‚ùå Training failed: {e}\")\n",
                "    mlflow_tracker.end_run(status=\"FAILED\")\n",
                "    raise"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Inference & Submission Generation\n",
                "\n",
                "Generate predictions on the test set and create submission file."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from ecg_digitization.inference import ECGPredictor\n",
                "\n",
                "print(\"\\nüîÆ Running inference on test set...\")\n",
                "\n",
                "# Prepare test dataset\n",
                "test_transform = get_val_transforms(tuple(cfg.data.image_size))\n",
                "test_dataset = ECGImageDataset(\n",
                "    cfg.paths.data_dir,\n",
                "    transform=test_transform,\n",
                "    is_train=False,\n",
                ")\n",
                "\n",
                "test_loader = DataLoader(\n",
                "    test_dataset,\n",
                "    batch_size=cfg.data.batch_size,\n",
                "    shuffle=False,\n",
                "    num_workers=cfg.data.num_workers,\n",
                "    collate_fn=collate_fn,\n",
                ")\n",
                "\n",
                "print(f\"  Test samples: {len(test_dataset)}\")\n",
                "\n",
                "# Load best model\n",
                "model = ECGDigitizer(\n",
                "    encoder_name=cfg.model.encoder_name,\n",
                "    num_leads=cfg.model.num_leads,\n",
                "    signal_length=cfg.model.signal_length,\n",
                ")\n",
                "\n",
                "predictor = ECGPredictor(\n",
                "    model=model,\n",
                "    checkpoint_path=f\"{cfg.paths.checkpoint_dir}/best_model.pt\",\n",
                "    device=device,\n",
                ")\n",
                "\n",
                "# Generate predictions\n",
                "predictions = predictor.predict(test_loader)\n",
                "print(f\"\\n‚úÖ Generated predictions for {len(predictions)} samples\")\n",
                "\n",
                "# Load test metadata\n",
                "test_csv = Path(cfg.paths.data_dir) / 'test.csv'\n",
                "if test_csv.exists():\n",
                "    metadata = pd.read_csv(test_csv)\n",
                "    print(f\"  Loaded metadata for {len(metadata)} test samples\")\n",
                "else:\n",
                "    metadata = None\n",
                "    print(\"  ‚ö†Ô∏è  No test metadata found\")\n",
                "\n",
                "# Generate submission file\n",
                "submission_path = Path(cfg.paths.submission_dir) / 'submission.parquet'\n",
                "predictor.generate_submission(\n",
                "    predictions,\n",
                "    str(submission_path),\n",
                "    metadata,\n",
                ")\n",
                "\n",
                "print(f\"\\nüìù Submission file created: {submission_path}\")\n",
                "print(f\"  File size: {submission_path.stat().st_size / 1024 / 1024:.2f} MB\")\n",
                "\n",
                "# Verify submission format\n",
                "if submission_path.exists():\n",
                "    submission_df = pd.read_parquet(submission_path)\n",
                "    print(f\"\\n‚úÖ Submission verification:\")\n",
                "    print(f\"  Shape: {submission_df.shape}\")\n",
                "    print(f\"  Columns: {list(submission_df.columns)}\")\n",
                "    display(submission_df.head())\n",
                "else:\n",
                "    print(\"\\n‚ùå Submission file not created!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Visualize Sample Predictions\n",
                "\n",
                "Display some sample predictions to verify quality."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize a few predictions\n",
                "num_samples = min(3, len(predictions))\n",
                "\n",
                "fig, axes = plt.subplots(num_samples, 1, figsize=(14, 4 * num_samples))\n",
                "if num_samples == 1:\n",
                "    axes = [axes]\n",
                "\n",
                "for idx in range(num_samples):\n",
                "    pred = predictions[idx]\n",
                "    time = np.arange(pred.shape[1]) / 500  # Assuming 500 Hz sampling rate\n",
                "    \n",
                "    # Plot all 12 leads\n",
                "    for lead_idx in range(min(12, pred.shape[0])):\n",
                "        axes[idx].plot(time, pred[lead_idx, :] + lead_idx * 2, linewidth=0.8, alpha=0.8)\n",
                "    \n",
                "    axes[idx].set_xlabel('Time (s)', fontsize=11)\n",
                "    axes[idx].set_ylabel('Lead (offset)', fontsize=11)\n",
                "    axes[idx].set_title(f'Sample {idx + 1} - Predicted ECG Signals', fontsize=12, fontweight='bold')\n",
                "    axes[idx].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\n‚úÖ Displayed {num_samples} sample predictions\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üéâ Submission Ready!\n",
                "\n",
                "Your submission file has been generated and is ready to submit to Kaggle.\n",
                "\n",
                "**Next Steps**:\n",
                "1. Download `submission.parquet` from the output directory\n",
                "2. Submit to the [PhysioNet ECG Image Digitization competition](https://www.kaggle.com/competitions/physionet-ecg-image-digitization)\n",
                "3. Check your leaderboard score!\n",
                "\n",
                "**Note**: MLflow tracking was disabled for this Kaggle run. To enable tracking locally with MLflow, set `mlflow.enabled=true` in the configuration."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        },
        "kaggle": {
            "accelerator": "none",
            "dataSources": [
                {
                    "sourceId": 97984,
                    "databundleVersionId": 14096757,
                    "isSourceIdPinned": false,
                    "sourceType": "competition"
                }
            ],
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook",
            "isGpuEnabled": false
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}